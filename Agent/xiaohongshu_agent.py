"""
å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆæ™ºèƒ½ä½“
åŸºäºLangChainå’ŒOllamaæ„å»ºçš„æ™ºèƒ½æ–‡æ¡ˆç”Ÿæˆå·¥å…·
"""

import json
import sys
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥LLMæ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from LLM.ollama_client import OllamaClient
from .i18n_agent import (
    Language, 
    get_prompt_template, 
    format_keywords_section, 
    format_special_requirements_section,
    translate_category
)

from langchain.agents import initialize_agent, AgentType
from langchain.tools import Tool
from langchain.memory import ConversationBufferMemory
from langchain.schema import BaseMessage, HumanMessage, AIMessage
from langchain.llms.base import LLM
from langchain.callbacks.manager import CallbackManagerForLLMRun
from pydantic import Field, ConfigDict


def get_language_instruction(language: Language) -> str:
    """æ ¹æ®è¯­è¨€ç±»å‹ç”Ÿæˆå¯¹åº”çš„è¯­è¨€æŒ‡ä»¤"""
    language_instructions = {
        Language.ZH_CN: "è¯·ç”¨ç®€ä½“ä¸­æ–‡å›ç­”",
        Language.EN_US: "IMPORTANT: You must respond ONLY in English. Do not use any Chinese characters. Write content in English language for English-speaking audience",
        Language.ZH_TW: "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸è¦ä½¿ç”¨ç°¡é«”å­—", 
        Language.JA_JP: "é‡è¦ï¼šå¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ä¸­å›½èªã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„"
    }
    return language_instructions.get(language, language_instructions[Language.ZH_CN])


def add_language_instruction_to_prompt(prompt: str, language: Language) -> str:
    """ä¸ºpromptæ·»åŠ è¯­è¨€æŒ‡ä»¤"""
    language_instruction = get_language_instruction(language)
    if language == Language.EN_US:
        # å¯¹è‹±è¯­æ·»åŠ æ›´å¼ºçš„æŒ‡ä»¤
        return f"{language_instruction}\n\nIMPORTANT: Your entire response must be in English. This includes the title, content, and hashtags.\n\n{prompt}\n\nRemember: Write EVERYTHING in English language."
    elif language == Language.JA_JP:
        # å¯¹æ—¥è¯­æ·»åŠ æ›´å¼ºçš„æŒ‡ä»¤
        return f"{language_instruction}\n\né‡è¦ï¼šå›ç­”ã®å…¨ã¦ã‚’æ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚\n\n{prompt}\n\næ³¨æ„ï¼šã‚¿ã‚¤ãƒˆãƒ«ã€å†…å®¹ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã™ã¹ã¦æ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚"
    elif language == Language.ZH_TW:
        # å¯¹ç¹ä½“ä¸­æ–‡æ·»åŠ æ›´å¼ºçš„æŒ‡ä»¤
        return f"{language_instruction}\n\né‡è¦ï¼šè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸è¦ä½¿ç”¨ç°¡é«”å­—ã€‚\n\n{prompt}\n\nè¨˜ä½ï¼šæ¨™é¡Œã€å…§å®¹ã€æ¨™ç±¤éƒ½è¦ç”¨ç¹é«”ä¸­æ–‡ã€‚"
    else:
        return f"{language_instruction}ã€‚\n\n{prompt}"


class ContentCategory(Enum):
    """å†…å®¹åˆ†ç±»æšä¸¾"""
    BEAUTY = "ç¾å¦†æŠ¤è‚¤"
    FASHION = "æ—¶å°šç©¿æ­"
    FOOD = "ç¾é£Ÿæ¢åº—"
    TRAVEL = "æ—…è¡Œæ”»ç•¥"
    LIFESTYLE = "ç”Ÿæ´»æ–¹å¼"
    FITNESS = "å¥èº«è¿åŠ¨"
    HOME = "å®¶å±…è£…é¥°"
    STUDY = "å­¦ä¹ åˆ†äº«"
    WORK = "èŒåœºå¹²è´§"
    SHOPPING = "å¥½ç‰©æ¨è"
    TECH = "ç§‘æŠ€æ•°ç "
    EMOTION = "æƒ…æ„Ÿç”Ÿæ´»"
    CAREER = "èŒåœºå‘å±•"
    EDUCATION = "æ•™è‚²å­¦ä¹ "


@dataclass
class ContentRequest:
    """å†…å®¹ç”Ÿæˆè¯·æ±‚"""
    category: ContentCategory
    topic: str
    tone: str = "æ´»æ³¼å¯çˆ±"
    length: str = "ä¸­ç­‰"
    keywords: List[str] = None
    target_audience: str = "å¹´è½»å¥³æ€§"
    special_requirements: str = ""
    language: str = "zh-CN"  # æ–°å¢è¯­è¨€å‚æ•°


class OllamaLangChainLLM(LLM):
    """å°†Ollamaå®¢æˆ·ç«¯é€‚é…ä¸ºLangChainçš„LLMæ¥å£"""
    
    model_config = ConfigDict(arbitrary_types_allowed=True)
    
    ollama_client: OllamaClient = Field(default_factory=lambda: OllamaClient())
    enable_stream: bool = Field(default=True)
    enable_thinking: bool = Field(default=True)
    
    @property
    def _llm_type(self) -> str:
        return "ollama"
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        """è°ƒç”¨Ollamaç”Ÿæˆæ–‡æœ¬"""
        # å¤„ç†æ€è€ƒæ¨¡å¼
        if not self.enable_thinking and not prompt.endswith("/no_think"):
            prompt += "/no_think"
        
        response = self.ollama_client.generate(prompt, stream=self.enable_stream)
        return response if response else "æŠ±æ­‰ï¼Œç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚"


class XiaohongshuAgent:
    """å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆæ™ºèƒ½ä½“"""
    
    def __init__(self, enable_stream: bool = True, enable_thinking: bool = True):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“
        
        Args:
            enable_stream: æ˜¯å¦å¯ç”¨æµå¼å“åº”
            enable_thinking: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼
        """
        self.ollama_client = OllamaClient()
        self.llm = OllamaLangChainLLM(
            enable_stream=enable_stream,
            enable_thinking=enable_thinking
        )
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        # å­˜å‚¨é…ç½®
        self.enable_stream = enable_stream
        self.enable_thinking = enable_thinking
        
        # åˆå§‹åŒ–å·¥å…·
        self.tools = self._create_tools()
        
        # åˆå§‹åŒ–æ™ºèƒ½ä½“
        self.agent = initialize_agent(
            tools=self.tools,
            llm=self.llm,
            agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
            memory=self.memory,
            verbose=True,
            handle_parsing_errors=True
        )
    
    def _create_tools(self) -> List[Tool]:
        """åˆ›å»ºæ™ºèƒ½ä½“ä½¿ç”¨çš„å·¥å…·"""
        
        def generate_title_tool(query: str) -> str:
            """ç”Ÿæˆå°çº¢ä¹¦æ ‡é¢˜çš„å·¥å…·"""
            # ä»æŸ¥è¯¢ä¸­æå–è¯­è¨€ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤è¯­è¨€
            language = Language.ZH_CN  # é»˜è®¤è¯­è¨€
            if "|language:" in query:
                query_parts = query.split("|language:")
                if len(query_parts) > 1:
                    # å¤„ç†è¯­è¨€ä»£ç ï¼Œå¯èƒ½åŒ…å«å…¶ä»–å†…å®¹
                    lang_part = query_parts[1]
                    # æå–è¯­è¨€ä»£ç ï¼ˆå–ç¬¬ä¸€ä¸ª|ä¹‹å‰çš„éƒ¨åˆ†ï¼‰
                    if "|" in lang_part:
                        lang_code = lang_part.split("|")[0].strip()
                    else:
                        lang_code = lang_part.strip()
                    try:
                        language = Language(lang_code)
                        # é‡æ–°æ„å»ºæŸ¥è¯¢ï¼Œå»æ‰è¯­è¨€æ ‡è®°
                        query = query_parts[0].strip()
                        if len(query_parts) > 1 and "|" in query_parts[1]:
                            remaining_parts = "|".join(query_parts[1].split("|")[1:])
                            if remaining_parts.strip():
                                query += "|" + remaining_parts
                    except ValueError:
                        language = Language.ZH_CN  # è§£æå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤è¯­è¨€
            
            prompt_template = get_prompt_template("title_generation", language)
            prompt = prompt_template.format(query=query)
            
            # æ·»åŠ è¯­è¨€æŒ‡ä»¤
            prompt = add_language_instruction_to_prompt(prompt, language)
            
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                prompt += "/no_think"
            
            return self.ollama_client.generate(prompt, stream=self.enable_stream) or "ç”Ÿæˆå¤±è´¥"
        
        def generate_content_tool(query: str) -> str:
            """ç”Ÿæˆå°çº¢ä¹¦æ­£æ–‡å†…å®¹çš„å·¥å…·"""
            # ä»æŸ¥è¯¢ä¸­æå–è¯­è¨€ä¿¡æ¯
            language = Language.ZH_CN  # é»˜è®¤è¯­è¨€
            if "|language:" in query:
                query_parts = query.split("|language:")
                if len(query_parts) > 1:
                    # å¤„ç†è¯­è¨€ä»£ç ï¼Œå¯èƒ½åŒ…å«å…¶ä»–å†…å®¹
                    lang_part = query_parts[1]
                    # æå–è¯­è¨€ä»£ç ï¼ˆå–ç¬¬ä¸€ä¸ª|ä¹‹å‰çš„éƒ¨åˆ†ï¼‰
                    if "|" in lang_part:
                        lang_code = lang_part.split("|")[0].strip()
                    else:
                        lang_code = lang_part.strip()
                    try:
                        language = Language(lang_code)
                        # é‡æ–°æ„å»ºæŸ¥è¯¢ï¼Œå»æ‰è¯­è¨€æ ‡è®°
                        query = query_parts[0].strip()
                        if len(query_parts) > 1 and "|" in query_parts[1]:
                            remaining_parts = "|".join(query_parts[1].split("|")[1:])
                            if remaining_parts.strip():
                                query += "|" + remaining_parts
                    except ValueError:
                        language = Language.ZH_CN  # è§£æå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤è¯­è¨€
            
            prompt_template = get_prompt_template("content_writing", language)
            prompt = prompt_template.format(query=query)
            
            # æ·»åŠ è¯­è¨€æŒ‡ä»¤
            prompt = add_language_instruction_to_prompt(prompt, language)
            
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                prompt += "/no_think"
            
            return self.ollama_client.generate(prompt, stream=self.enable_stream) or "ç”Ÿæˆå¤±è´¥"
        
        def generate_hashtags_tool(query: str) -> str:
            """ç”Ÿæˆå°çº¢ä¹¦è¯é¢˜æ ‡ç­¾çš„å·¥å…·"""
            # ä»æŸ¥è¯¢ä¸­æå–è¯­è¨€ä¿¡æ¯
            language = Language.ZH_CN  # é»˜è®¤è¯­è¨€
            if "|language:" in query:
                query_parts = query.split("|language:")
                if len(query_parts) > 1:
                    # å¤„ç†è¯­è¨€ä»£ç ï¼Œå¯èƒ½åŒ…å«å…¶ä»–å†…å®¹
                    lang_part = query_parts[1]
                    # æå–è¯­è¨€ä»£ç ï¼ˆå–ç¬¬ä¸€ä¸ª|ä¹‹å‰çš„éƒ¨åˆ†ï¼‰
                    if "|" in lang_part:
                        lang_code = lang_part.split("|")[0].strip()
                    else:
                        lang_code = lang_part.strip()
                    try:
                        language = Language(lang_code)
                        # é‡æ–°æ„å»ºæŸ¥è¯¢ï¼Œå»æ‰è¯­è¨€æ ‡è®°
                        query = query_parts[0].strip()
                        if len(query_parts) > 1 and "|" in query_parts[1]:
                            remaining_parts = "|".join(query_parts[1].split("|")[1:])
                            if remaining_parts.strip():
                                query += "|" + remaining_parts
                    except ValueError:
                        language = Language.ZH_CN  # è§£æå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤è¯­è¨€
            
            prompt_template = get_prompt_template("hashtag_generation", language)
            prompt = prompt_template.format(query=query)
            
            # æ·»åŠ è¯­è¨€æŒ‡ä»¤
            prompt = add_language_instruction_to_prompt(prompt, language)
            
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                prompt += "/no_think"
            
            return self.ollama_client.generate(prompt, stream=self.enable_stream) or "ç”Ÿæˆå¤±è´¥"
        
        def content_optimization_tool(query: str) -> str:
            """å†…å®¹ä¼˜åŒ–å»ºè®®å·¥å…·"""
            # ä»æŸ¥è¯¢ä¸­æå–è¯­è¨€ä¿¡æ¯
            language = Language.ZH_CN  # é»˜è®¤è¯­è¨€
            if "|language:" in query:
                query_parts = query.split("|language:")
                if len(query_parts) > 1:
                    # å¤„ç†è¯­è¨€ä»£ç ï¼Œå¯èƒ½åŒ…å«å…¶ä»–å†…å®¹
                    lang_part = query_parts[1]
                    # æå–è¯­è¨€ä»£ç ï¼ˆå–ç¬¬ä¸€ä¸ª|ä¹‹å‰çš„éƒ¨åˆ†ï¼‰
                    if "|" in lang_part:
                        lang_code = lang_part.split("|")[0].strip()
                    else:
                        lang_code = lang_part.strip()
                    try:
                        language = Language(lang_code)
                        # é‡æ–°æ„å»ºæŸ¥è¯¢ï¼Œå»æ‰è¯­è¨€æ ‡è®°
                        query = query_parts[0].strip()
                        if len(query_parts) > 1 and "|" in query_parts[1]:
                            remaining_parts = "|".join(query_parts[1].split("|")[1:])
                            if remaining_parts.strip():
                                query += "|" + remaining_parts
                    except ValueError:
                        language = Language.ZH_CN  # è§£æå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤è¯­è¨€
            
            prompt_template = get_prompt_template("content_optimization", language)
            prompt = prompt_template.format(content=query)
            
            # æ·»åŠ è¯­è¨€æŒ‡ä»¤
            prompt = add_language_instruction_to_prompt(prompt, language)
            
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                prompt += "/no_think"
            
            return self.ollama_client.generate(prompt, stream=self.enable_stream) or "ç”Ÿæˆå¤±è´¥"
        
        return [
            Tool(
                name="ç”Ÿæˆæ ‡é¢˜",
                func=generate_title_tool,
                description="ä¸ºå°çº¢ä¹¦å†…å®¹ç”Ÿæˆå¸å¼•äººçš„æ ‡é¢˜ï¼Œè¾“å…¥å†…å®¹æè¿°å³å¯"
            ),
            Tool(
                name="ç”Ÿæˆæ­£æ–‡",
                func=generate_content_tool,
                description="æ ¹æ®éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦æ–‡æ¡ˆæ­£æ–‡å†…å®¹"
            ),
            Tool(
                name="ç”Ÿæˆè¯é¢˜æ ‡ç­¾",
                func=generate_hashtags_tool,
                description="ä¸ºå°çº¢ä¹¦å†…å®¹ç”Ÿæˆç›¸å…³çš„è¯é¢˜æ ‡ç­¾"
            ),
            Tool(
                name="å†…å®¹ä¼˜åŒ–",
                func=content_optimization_tool,
                description="å¯¹å·²æœ‰çš„å°çº¢ä¹¦æ–‡æ¡ˆæä¾›ä¼˜åŒ–å»ºè®®å’Œæ”¹è¿›æ–¹æ¡ˆ"
            )
        ]
    
    def check_setup(self) -> bool:
        """æ£€æŸ¥æ™ºèƒ½ä½“è®¾ç½®çŠ¶æ€"""
        print("ğŸ” æ­£åœ¨æ£€æŸ¥æ™ºèƒ½ä½“è®¾ç½®...")
        
        # æ£€æŸ¥Ollamaè¿æ¥
        if not self.ollama_client.check_connection():
            print("âŒ OllamaæœåŠ¡è¿æ¥å¤±è´¥")
            return False
        print("âœ… OllamaæœåŠ¡è¿æ¥æ­£å¸¸")
        
        # æ£€æŸ¥æ¨¡å‹
        if not self.ollama_client.check_model_exists():
            print("âš ï¸  æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¸‹è½½...")
            if not self.ollama_client.pull_model():
                print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
                return False
        print("âœ… æ¨¡å‹å‡†å¤‡å°±ç»ª")
        
        return True
    
    def generate_complete_post(self, request: ContentRequest) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦æ–‡æ¡ˆ"""
        
        try:
            # è·å–è¯­è¨€å‚æ•°
            language = Language(request.language) if hasattr(request, 'language') and request.language else Language.ZH_CN
        except ValueError:
            language = Language.ZH_CN
        
        # ä½¿ç”¨å›½é™…åŒ–æ¨¡æ¿æ„å»ºéœ€æ±‚æè¿°
        prompt_template = get_prompt_template("content_generation", language)
        
        # æ ¼å¼åŒ–å…³é”®è¯å’Œç‰¹æ®Šè¦æ±‚
        keywords_section = format_keywords_section(request.keywords, language)
        special_requirements_section = format_special_requirements_section(request.special_requirements, language)
        
        # ç¿»è¯‘åˆ†ç±»åˆ°ç›®æ ‡è¯­è¨€
        translated_category = translate_category(request.category.value, language)
        
        requirement = prompt_template.format(
            category=translated_category,
            topic=request.topic,
            tone=request.tone,
            length=request.length,
            target_audience=request.target_audience,
            keywords_section=keywords_section,
            special_requirements_section=special_requirements_section
        )
        
        # æ·»åŠ è¯­è¨€æŒ‡ä»¤å’Œè¯­è¨€æ ‡è®°
        requirement = add_language_instruction_to_prompt(requirement, language)
        requirement = f"|language:{request.language}|{requirement}"
        
        try:
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                requirement += "/no_think"
            
            # ç›´æ¥ä½¿ç”¨ Ollama å®¢æˆ·ç«¯ç”Ÿæˆå†…å®¹ï¼Œé¿å… LangChain Agent çš„ä¸­æ–‡å¹²æ‰°
            result = self.ollama_client.generate(requirement, stream=self.enable_stream)
            
            return {
                "success": True,
                "content": result,
                "request": request.__dict__
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "request": request.__dict__
            }
    
    def optimize_content(self, content: str, language: str = "zh-CN") -> Dict[str, Any]:
        """ä¼˜åŒ–ç°æœ‰å†…å®¹"""
        try:
            # è·å–è¯­è¨€å‚æ•°
            try:
                lang = Language(language)
            except ValueError:
                lang = Language.ZH_CN
            
            # ä½¿ç”¨å›½é™…åŒ–æ¨¡æ¿
            prompt_template = get_prompt_template("content_optimization", lang)
            optimization_query = prompt_template.format(content=content)
            
            # æ·»åŠ è¯­è¨€æŒ‡ä»¤
            optimization_query = add_language_instruction_to_prompt(optimization_query, lang)
            
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                optimization_query += "/no_think"
            
            # ç›´æ¥ä½¿ç”¨ Ollama å®¢æˆ·ç«¯ï¼Œé¿å… LangChain Agent çš„ä¸­æ–‡å¹²æ‰°
            result = self.ollama_client.generate(optimization_query, stream=self.enable_stream)
            
            return {
                "success": True,
                "original": content,
                "optimized": result
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "original": content
            }
    
    def chat(self, message: str, language: str = "zh-CN") -> str:
        """ä¸æ™ºèƒ½ä½“å¯¹è¯"""
        try:
            # ä¸ºèŠå¤©æ¶ˆæ¯æ·»åŠ è¯­è¨€ä¸Šä¸‹æ–‡
            try:
                lang = Language(language)
            except ValueError:
                lang = Language.ZH_CN
            
            # ä½¿ç”¨æ ‡å‡†åŒ–çš„è¯­è¨€æŒ‡ä»¤ï¼Œå¹¶å°†è¯­è¨€ä¿¡æ¯é™„åŠ åˆ°æ¶ˆæ¯ä¸­
            language_instruction = get_language_instruction(lang)
            contextualized_message = f"{language_instruction}ã€‚|language:{language}|ç”¨æˆ·æ¶ˆæ¯ï¼š{message}"
            
            response = self.agent.run(contextualized_message)
            return response
        except Exception as e:
            # æ ¹æ®è¯­è¨€è¿”å›é”™è¯¯æ¶ˆæ¯
            error_messages = {
                Language.ZH_CN: f"å¯¹è¯å‡ºé”™ï¼š{str(e)}",
                Language.EN_US: f"Chat error: {str(e)}",
                Language.ZH_TW: f"å°è©±å‡ºéŒ¯ï¼š{str(e)}",
                Language.JA_JP: f"ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼ï¼š{str(e)}"
            }
            try:
                lang = Language(language)
                return error_messages.get(lang, error_messages[Language.ZH_CN])
            except ValueError:
                return error_messages[Language.ZH_CN]
    
    def update_config(self, enable_stream: bool = None, enable_thinking: bool = None):
        """æ›´æ–°é…ç½®"""
        if enable_stream is not None:
            self.enable_stream = enable_stream
            self.llm.enable_stream = enable_stream
        
        if enable_thinking is not None:
            self.enable_thinking = enable_thinking
            self.llm.enable_thinking = enable_thinking
    
    def generate_complete_post_stream(self, request: ContentRequest, enable_thinking: bool = None):
        """æµå¼ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦æ–‡æ¡ˆ"""
        
        try:
            # è·å–è¯­è¨€å‚æ•°
            language = Language(request.language) if hasattr(request, 'language') and request.language else Language.ZH_CN
        except ValueError:
            language = Language.ZH_CN
        
        # ä½¿ç”¨å›½é™…åŒ–æ¨¡æ¿æ„å»ºéœ€æ±‚æè¿°
        prompt_template = get_prompt_template("content_generation", language)
        
        # æ ¼å¼åŒ–å…³é”®è¯å’Œç‰¹æ®Šè¦æ±‚
        keywords_section = format_keywords_section(request.keywords, language)
        special_requirements_section = format_special_requirements_section(request.special_requirements, language)
        
        # ç¿»è¯‘åˆ†ç±»åˆ°ç›®æ ‡è¯­è¨€
        translated_category = translate_category(request.category.value, language)
        
        requirement = prompt_template.format(
            category=translated_category,
            topic=request.topic,
            tone=request.tone,
            length=request.length,
            target_audience=request.target_audience,
            keywords_section=keywords_section,
            special_requirements_section=special_requirements_section
        )
        
        # æ·»åŠ è¯­è¨€æŒ‡ä»¤
        requirement = add_language_instruction_to_prompt(requirement, language)
        
        # å¤„ç†æ€è€ƒæ¨¡å¼ - ä¼˜å…ˆä½¿ç”¨å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨å®ä¾‹è®¾ç½®
        thinking_enabled = enable_thinking if enable_thinking is not None else self.enable_thinking
        if not thinking_enabled:
            requirement += "/no_think"
        
        # å‡†å¤‡ç³»ç»Ÿçº§è¯­è¨€æç¤º
        system_prompt = None
        if language == Language.EN_US:
            system_prompt = "You are a professional content creator for Xiaohongshu (Little Red Book). You must respond ONLY in English. Never use Chinese characters in your response."
        elif language == Language.JA_JP:
            system_prompt = "ã‚ãªãŸã¯å°ç´…æ›¸ï¼ˆã‚·ãƒ£ã‚ªãƒ›ãƒ³ã‚·ãƒ¥ãƒ¼ï¼‰ã®ãƒ—ãƒ­ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚å¿…ãšæ—¥æœ¬èªã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ä¸­å›½èªã¯æ±ºã—ã¦ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚"
        elif language == Language.ZH_TW:
            system_prompt = "æ‚¨æ˜¯å°ç´…æ›¸çš„å°ˆæ¥­å…§å®¹å‰µä½œè€…ã€‚è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸è¦ä½¿ç”¨ç°¡é«”å­—ã€‚"
        
        # ä½¿ç”¨æµå¼ç”Ÿæˆå™¨ï¼Œä¼ é€’ç³»ç»Ÿæç¤º
        return self.ollama_client.generate_stream(requirement, system_prompt)

    def chat_stream(self, message: str, language: str = "zh-CN", enable_thinking: bool = None):
        """æµå¼å¯¹è¯"""
        try:
            # ä¸ºèŠå¤©æ¶ˆæ¯æ·»åŠ è¯­è¨€ä¸Šä¸‹æ–‡
            try:
                lang = Language(language)
            except ValueError:
                lang = Language.ZH_CN
            
            # ä½¿ç”¨æ ‡å‡†åŒ–çš„è¯­è¨€æŒ‡ä»¤ï¼Œå¹¶å°†è¯­è¨€ä¿¡æ¯é™„åŠ åˆ°æ¶ˆæ¯ä¸­
            language_instruction = get_language_instruction(lang)
            contextualized_message = f"{language_instruction}ã€‚|language:{language}|ç”¨æˆ·æ¶ˆæ¯ï¼š{message}"
            
            # å¤„ç†æ€è€ƒæ¨¡å¼ - ä¼˜å…ˆä½¿ç”¨å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨å®ä¾‹è®¾ç½®
            thinking_enabled = enable_thinking if enable_thinking is not None else self.enable_thinking
            if not thinking_enabled and not contextualized_message.endswith("/no_think"):
                contextualized_message += "/no_think"
            
            # æ„å»ºå¯¹è¯æ¶ˆæ¯
            messages = [{"role": "user", "content": contextualized_message}]
            
            # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
            chat_history = self.memory.chat_memory.messages
            if chat_history:
                # è½¬æ¢LangChainæ¶ˆæ¯æ ¼å¼åˆ°Ollamaæ ¼å¼
                for msg in chat_history[-10:]:  # åªä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
                    if hasattr(msg, 'content'):
                        if isinstance(msg, HumanMessage):
                            messages.insert(-1, {"role": "user", "content": msg.content})
                        elif isinstance(msg, AIMessage):
                            messages.insert(-1, {"role": "assistant", "content": msg.content})
            
            # ä½¿ç”¨æµå¼ç”Ÿæˆå™¨
            return self.ollama_client.chat_stream(messages)
        except Exception as e:
            def error_generator():
                # æ ¹æ®è¯­è¨€è¿”å›é”™è¯¯æ¶ˆæ¯
                error_messages = {
                    Language.ZH_CN: f"å¯¹è¯å‡ºé”™ï¼š{str(e)}",
                    Language.EN_US: f"Chat error: {str(e)}",
                    Language.ZH_TW: f"å°è©±å‡ºéŒ¯ï¼š{str(e)}",
                    Language.JA_JP: f"ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼ï¼š{str(e)}"
                }
                try:
                    lang = Language(language)
                    yield error_messages.get(lang, error_messages[Language.ZH_CN])
                except ValueError:
                    yield error_messages[Language.ZH_CN]
            return error_generator()

    def optimize_content_stream(self, content: str, language: str = "zh-CN", enable_thinking: bool = None):
        """æµå¼ä¼˜åŒ–ç°æœ‰å†…å®¹"""
        try:
            # è·å–è¯­è¨€å‚æ•°
            lang = Language(language)
        except ValueError:
            lang = Language.ZH_CN
        
        # ä½¿ç”¨å›½é™…åŒ–æ¨¡æ¿
        prompt_template = get_prompt_template("content_optimization", lang)
        optimization_query = prompt_template.format(content=content)
        
        # æ·»åŠ è¯­è¨€æŒ‡ä»¤
        optimization_query = add_language_instruction_to_prompt(optimization_query, lang)
        
        # å¤„ç†æ€è€ƒæ¨¡å¼ - ä¼˜å…ˆä½¿ç”¨å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨å®ä¾‹è®¾ç½®
        thinking_enabled = enable_thinking if enable_thinking is not None else self.enable_thinking
        if not thinking_enabled:
            optimization_query += "/no_think"
        
        # å‡†å¤‡ç³»ç»Ÿçº§è¯­è¨€æç¤º
        system_prompt = None
        if lang == Language.EN_US:
            system_prompt = "You are a professional content optimizer for Xiaohongshu (Little Red Book). You must respond ONLY in English. Never use Chinese characters in your response."
        elif lang == Language.JA_JP:
            system_prompt = "ã‚ãªãŸã¯å°ç´…æ›¸ï¼ˆã‚·ãƒ£ã‚ªãƒ›ãƒ³ã‚·ãƒ¥ãƒ¼ï¼‰ã®ãƒ—ãƒ­ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æœ€é©åŒ–å°‚é–€å®¶ã§ã™ã€‚å¿…ãšæ—¥æœ¬èªã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ä¸­å›½èªã¯æ±ºã—ã¦ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚"
        elif lang == Language.ZH_TW:
            system_prompt = "æ‚¨æ˜¯å°ç´…æ›¸ã®å°ˆæ¥­å…§å®¹å„ªåŒ–å°ˆå®¶ã€‚è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸è¦ä½¿ç”¨ç°¡é«”å­—ã€‚"
        
        # ä½¿ç”¨æµå¼ç”Ÿæˆå™¨ï¼Œä¼ é€’ç³»ç»Ÿæç¤º
        return self.ollama_client.generate_stream(optimization_query, system_prompt)

    def intelligent_loop(self, content: str, user_feedback: str, content_request: ContentRequest = None, language: str = "zh-CN"):
        """æ™ºèƒ½ä½“å›ç¯å¤„ç†
        
        Args:
            content: å½“å‰ç”Ÿæˆçš„å†…å®¹
            user_feedback: ç”¨æˆ·åé¦ˆ ("ä¸æ»¡æ„", "æ»¡æ„", "éœ€è¦ä¼˜åŒ–", "é‡æ–°ç”Ÿæˆ")
            content_request: åŸå§‹å†…å®¹è¯·æ±‚ï¼Œç”¨äºé‡æ–°ç”Ÿæˆ
            language: å›å¤è¯­è¨€ï¼Œé»˜è®¤ç®€ä½“ä¸­æ–‡
            
        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        # è·å–è¯­è¨€å‚æ•°
        try:
            lang = Language(language)
        except ValueError:
            lang = Language.ZH_CN
        
        # å®šä¹‰å¤šè¯­è¨€æ¶ˆæ¯
        messages = {
            Language.ZH_CN: {
                "satisfied_ask": "å¾ˆé«˜å…´æ‚¨æ»¡æ„è¿™ä¸ªæ–‡æ¡ˆï¼æ˜¯å¦éœ€è¦æˆ‘è¿›ä¸€æ­¥ä¼˜åŒ–å†…å®¹ï¼Ÿ",
                "completed": "åˆ›ä½œå®Œæˆï¼å¦‚éœ€è¦æ–°çš„æ–‡æ¡ˆï¼Œè¯·å¼€å§‹æ–°çš„åˆ›ä½œæµç¨‹ã€‚",
                "unknown_feedback": "è¯·é€‰æ‹©ï¼šä¸æ»¡æ„ã€æ»¡æ„ã€éœ€è¦ä¼˜åŒ– æˆ– ä¸éœ€è¦ä¼˜åŒ–ï¼Œå·²å®Œæˆ",
                "error_occurred": "å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·é‡è¯•",
                "options": ["éœ€è¦ä¼˜åŒ–", "ä¸éœ€è¦ä¼˜åŒ–ï¼Œå·²å®Œæˆ"]
            },
            Language.EN_US: {
                "satisfied_ask": "Glad you're satisfied with this content! Would you like me to further optimize it?",
                "completed": "Creation completed! Start a new creation process if you need new content.",
                "unknown_feedback": "Please choose: Not satisfied, Satisfied, Need optimization, or No optimization needed, completed",
                "error_occurred": "An error occurred during processing, please try again",
                "options": ["Need optimization", "No optimization needed, completed"]
            },
            Language.ZH_TW: {
                "satisfied_ask": "å¾ˆé«˜èˆˆæ‚¨æ»¿æ„é€™å€‹æ–‡æ¡ˆï¼æ˜¯å¦éœ€è¦æˆ‘é€²ä¸€æ­¥å„ªåŒ–å…§å®¹ï¼Ÿ",
                "completed": "å‰µä½œå®Œæˆï¼å¦‚éœ€è¦æ–°çš„æ–‡æ¡ˆï¼Œè«‹é–‹å§‹æ–°çš„å‰µä½œæµç¨‹ã€‚",
                "unknown_feedback": "è«‹é¸æ“‡ï¼šä¸æ»¿æ„ã€æ»¿æ„ã€éœ€è¦å„ªåŒ– æˆ– ä¸éœ€è¦å„ªåŒ–ï¼Œå·²å®Œæˆ",
                "error_occurred": "è™•ç†éç¨‹ä¸­å‡ºç¾éŒ¯èª¤ï¼Œè«‹é‡è©¦",
                "options": ["éœ€è¦å„ªåŒ–", "ä¸éœ€è¦å„ªåŒ–ï¼Œå·²å®Œæˆ"]
            },
            Language.JA_JP: {
                "satisfied_ask": "ã“ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«æº€è¶³ã—ã¦ã„ãŸã ã‘ã¦å¬‰ã—ã„ã§ã™ï¼ã•ã‚‰ã«æœ€é©åŒ–ã—ã¾ã™ã‹ï¼Ÿ",
                "completed": "ä½œæˆå®Œäº†ï¼æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå¿…è¦ãªå ´åˆã¯ã€æ–°ã—ã„ä½œæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚",
                "unknown_feedback": "é¸æŠã—ã¦ãã ã•ã„ï¼šä¸æº€ã€æº€è¶³ã€æœ€é©åŒ–ãŒå¿…è¦ã€ã¾ãŸã¯æœ€é©åŒ–ä¸è¦ã€å®Œäº†",
                "error_occurred": "å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„",
                "options": ["æœ€é©åŒ–ãŒå¿…è¦", "æœ€é©åŒ–ä¸è¦ã€å®Œäº†"]
            }
        }
        
        try:
            if user_feedback == "ä¸æ»¡æ„" or user_feedback == "é‡æ–°ç”Ÿæˆ":
                # ç”¨æˆ·ä¸æ»¡æ„ï¼Œé‡æ–°ç”Ÿæˆå†…å®¹
                if content_request:
                    return self.regenerate_with_improvements(content_request, content)
                else:
                    # å¦‚æœæ²¡æœ‰åŸå§‹è¯·æ±‚ï¼Œå°è¯•ä»å†…å®¹ä¸­æ¨æ–­å¹¶é‡æ–°ç”Ÿæˆ
                    return self.regenerate_from_content(content, language)
                    
            elif user_feedback == "æ»¡æ„":
                # ç”¨æˆ·æ»¡æ„ï¼Œè¯¢é—®æ˜¯å¦éœ€è¦ä¼˜åŒ–
                return {
                    "success": True,
                    "action": "ask_optimization",
                    "message": messages[lang]["satisfied_ask"],
                    "options": messages[lang]["options"]
                }
                
            elif user_feedback == "éœ€è¦ä¼˜åŒ–":
                # ç”¨æˆ·éœ€è¦ä¼˜åŒ–ï¼Œæ‰§è¡Œæ™ºèƒ½ä¼˜åŒ–
                return self.optimize_content(content, language)
                
            elif user_feedback == "ä¸éœ€è¦ä¼˜åŒ–ï¼Œå·²å®Œæˆ":
                # ç”¨æˆ·å®Œå…¨æ»¡æ„ï¼Œç»“æŸæµç¨‹
                return {
                    "success": True,
                    "action": "completed",
                    "message": messages[lang]["completed"],
                    "final_content": content
                }
                
            else:
                # æœªçŸ¥åé¦ˆï¼Œæä¾›å¸®åŠ©
                return {
                    "success": False,
                    "error": "æœªè¯†åˆ«çš„åé¦ˆç±»å‹",
                    "message": messages[lang]["unknown_feedback"]
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": messages[lang]["error_occurred"]
            }
    
    def regenerate_with_improvements(self, request: ContentRequest, previous_content: str):
        """åŸºäºç”¨æˆ·ä¸æ»¡æ„é‡æ–°ç”Ÿæˆæ”¹è¿›ç‰ˆæœ¬"""
        try:
            # è·å–è¯­è¨€å‚æ•°
            try:
                language = Language(request.language) if hasattr(request, 'language') and request.language else Language.ZH_CN
            except ValueError:
                language = Language.ZH_CN
            
            # å®šä¹‰å¤šè¯­è¨€æ¶ˆæ¯
            messages = {
                Language.ZH_CN: "å·²é‡æ–°ç”Ÿæˆæ”¹è¿›ç‰ˆæœ¬ï¼Œè¯·æŸ¥çœ‹æ˜¯å¦æ»¡æ„",
                Language.EN_US: "Regenerated improved version, please check if you're satisfied",
                Language.ZH_TW: "å·²é‡æ–°ç”Ÿæˆæ”¹é€²ç‰ˆæœ¬ï¼Œè«‹æŸ¥çœ‹æ˜¯å¦æ»¿æ„",
                Language.JA_JP: "æ”¹è‰¯ç‰ˆã‚’å†ç”Ÿæˆã—ã¾ã—ãŸã€‚æº€è¶³ã„ãŸã ã‘ã‚‹ã‹ã”ç¢ºèªãã ã•ã„"
            }
            
            # ä½¿ç”¨å›½é™…åŒ–æ¨¡æ¿
            prompt_template = get_prompt_template("regeneration_with_improvements", language)
            
            # æ ¼å¼åŒ–å…³é”®è¯å’Œç‰¹æ®Šè¦æ±‚
            keywords_section = format_keywords_section(request.keywords, language)
            special_requirements_section = format_special_requirements_section(request.special_requirements, language)
            
            # ç¿»è¯‘åˆ†ç±»åˆ°ç›®æ ‡è¯­è¨€
            translated_category = translate_category(request.category.value, language)
            
            improvement_prompt = prompt_template.format(
                category=translated_category,
                topic=request.topic,
                tone=request.tone,
                length=request.length,
                target_audience=request.target_audience,
                keywords_section=keywords_section,
                special_requirements_section=special_requirements_section,
                previous_content=previous_content
            )
            
            # æ·»åŠ è¯­è¨€æŒ‡ä»¤
            improvement_prompt = add_language_instruction_to_prompt(improvement_prompt, language)
            
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                improvement_prompt += "/no_think"
            
            result = self.ollama_client.generate(improvement_prompt, stream=self.enable_stream)
            
            return {
                "success": True,
                "action": "regenerated",
                "content": result,
                "message": messages[language]
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "action": "error"
            }
    
    def regenerate_from_content(self, content: str, language: str = "zh-CN"):
        """ä»ç°æœ‰å†…å®¹æ¨æ–­éœ€æ±‚å¹¶é‡æ–°ç”Ÿæˆ"""
        try:
            # è·å–è¯­è¨€å‚æ•°
            try:
                lang = Language(language)
            except ValueError:
                lang = Language.ZH_CN
            
            # å®šä¹‰å¤šè¯­è¨€æ¶ˆæ¯
            messages = {
                Language.ZH_CN: "å·²åŸºäºåŸå†…å®¹é‡æ–°ç”Ÿæˆæ”¹è¿›ç‰ˆæœ¬",
                Language.EN_US: "Regenerated improved version based on original content",
                Language.ZH_TW: "å·²åŸºæ–¼åŸå…§å®¹é‡æ–°ç”Ÿæˆæ”¹é€²ç‰ˆæœ¬",
                Language.JA_JP: "å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«åŸºã¥ã„ã¦æ”¹è‰¯ç‰ˆã‚’å†ç”Ÿæˆã—ã¾ã—ãŸ"
            }
            
            # ä½¿ç”¨å›½é™…åŒ–æ¨¡æ¿
            prompt_template = get_prompt_template("regeneration_from_content", lang)
            regeneration_prompt = prompt_template.format(content=content)
            
            # æ·»åŠ è¯­è¨€æŒ‡ä»¤
            regeneration_prompt = add_language_instruction_to_prompt(regeneration_prompt, lang)
            
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                regeneration_prompt += "/no_think"
            
            result = self.ollama_client.generate(regeneration_prompt, stream=self.enable_stream)
            
            return {
                "success": True,
                "action": "regenerated", 
                "content": result,
                "message": messages[lang]
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "action": "error"
            }
    
    def intelligent_loop_stream(self, content: str, user_feedback: str, content_request: ContentRequest = None, language: str = "zh-CN"):
        """æµå¼æ™ºèƒ½ä½“å›ç¯å¤„ç†"""
        # è·å–è¯­è¨€å‚æ•°
        try:
            lang = Language(language)
        except ValueError:
            lang = Language.ZH_CN
        
        # å®šä¹‰å¤šè¯­è¨€æ¶ˆæ¯
        messages = {
            Language.ZH_CN: {
                "satisfied": "å¾ˆé«˜å…´æ‚¨æ»¡æ„è¿™ä¸ªæ–‡æ¡ˆï¼æ˜¯å¦éœ€è¦æˆ‘è¿›ä¸€æ­¥ä¼˜åŒ–å†…å®¹ï¼Ÿ",
                "completed": "åˆ›ä½œå®Œæˆï¼å¦‚éœ€è¦æ–°çš„æ–‡æ¡ˆï¼Œè¯·å¼€å§‹æ–°çš„åˆ›ä½œæµç¨‹ã€‚",
                "unknown": "è¯·é€‰æ‹©ï¼šä¸æ»¡æ„ã€æ»¡æ„ã€éœ€è¦ä¼˜åŒ– æˆ– ä¸éœ€è¦ä¼˜åŒ–ï¼Œå·²å®Œæˆ",
                "error": "å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š"
            },
            Language.EN_US: {
                "satisfied": "Glad you're satisfied with this content! Would you like me to further optimize it?",
                "completed": "Creation completed! Start a new creation process if you need new content.",
                "unknown": "Please choose: Not satisfied, Satisfied, Need optimization, or No optimization needed, completed",
                "error": "An error occurred during processing: "
            },
            Language.ZH_TW: {
                "satisfied": "å¾ˆé«˜èˆˆæ‚¨æ»¿æ„é€™å€‹æ–‡æ¡ˆï¼æ˜¯å¦éœ€è¦æˆ‘é€²ä¸€æ­¥å„ªåŒ–å…§å®¹ï¼Ÿ",
                "completed": "å‰µä½œå®Œæˆï¼å¦‚éœ€è¦æ–°çš„æ–‡æ¡ˆï¼Œè«‹é–‹å§‹æ–°çš„å‰µä½œæµç¨‹ã€‚",
                "unknown": "è«‹é¸æ“‡ï¼šä¸æ»¿æ„ã€æ»¿æ„ã€éœ€è¦å„ªåŒ– æˆ– ä¸éœ€è¦å„ªåŒ–ï¼Œå·²å®Œæˆ",
                "error": "è™•ç†éç¨‹ä¸­å‡ºç¾éŒ¯èª¤ï¼š"
            },
            Language.JA_JP: {
                "satisfied": "ã“ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«æº€è¶³ã—ã¦ã„ãŸã ã‘ã¦å¬‰ã—ã„ã§ã™ï¼ã•ã‚‰ã«æœ€é©åŒ–ã—ã¾ã™ã‹ï¼Ÿ",
                "completed": "ä½œæˆå®Œäº†ï¼æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå¿…è¦ãªå ´åˆã¯ã€æ–°ã—ã„ä½œæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚",
                "unknown": "é¸æŠã—ã¦ãã ã•ã„ï¼šä¸æº€ã€æº€è¶³ã€æœ€é©åŒ–ãŒå¿…è¦ã€ã¾ãŸã¯æœ€é©åŒ–ä¸è¦ã€å®Œäº†",
                "error": "å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š"
            }
        }
        
        try:
            if user_feedback == "ä¸æ»¡æ„" or user_feedback == "é‡æ–°ç”Ÿæˆ":
                # é‡æ–°ç”Ÿæˆæµå¼ç‰ˆæœ¬
                if content_request:
                    return self.regenerate_with_improvements_stream(content_request, content)
                else:
                    return self.regenerate_from_content_stream(content, language)
                    
            elif user_feedback == "éœ€è¦ä¼˜åŒ–":
                # æµå¼ä¼˜åŒ–
                return self.optimize_content_stream(content, language)
                
            else:
                # å¯¹äºå…¶ä»–æƒ…å†µï¼Œè¿”å›ç®€å•çš„ç”Ÿæˆå™¨
                def simple_response():
                    if user_feedback == "æ»¡æ„":
                        yield messages[lang]["satisfied"]
                    elif user_feedback == "ä¸éœ€è¦ä¼˜åŒ–ï¼Œå·²å®Œæˆ":
                        yield messages[lang]["completed"]
                    else:
                        yield messages[lang]["unknown"]
                
                return simple_response()
                
        except Exception as e:
            def error_response():
                yield f"{messages[lang]['error']}{str(e)}"
            return error_response()
    
    def regenerate_with_improvements_stream(self, request: ContentRequest, previous_content: str):
        """æµå¼é‡æ–°ç”Ÿæˆæ”¹è¿›ç‰ˆæœ¬"""
        # è·å–è¯­è¨€å‚æ•°
        try:
            language = Language(request.language) if hasattr(request, 'language') and request.language else Language.ZH_CN
        except ValueError:
            language = Language.ZH_CN
        
        # ä½¿ç”¨å›½é™…åŒ–æ¨¡æ¿
        prompt_template = get_prompt_template("regeneration_with_improvements", language)
        
        # æ ¼å¼åŒ–å…³é”®è¯å’Œç‰¹æ®Šè¦æ±‚
        keywords_section = format_keywords_section(request.keywords, language)
        special_requirements_section = format_special_requirements_section(request.special_requirements, language)
        
        # ç¿»è¯‘åˆ†ç±»åˆ°ç›®æ ‡è¯­è¨€
        translated_category = translate_category(request.category.value, language)
        
        improvement_prompt = prompt_template.format(
            category=translated_category,
            topic=request.topic,
            tone=request.tone,
            length=request.length,
            target_audience=request.target_audience,
            keywords_section=keywords_section,
            special_requirements_section=special_requirements_section,
            previous_content=previous_content
        )
        
        # æ·»åŠ è¯­è¨€æŒ‡ä»¤
        improvement_prompt = add_language_instruction_to_prompt(improvement_prompt, language)
        
        # å¤„ç†æ€è€ƒæ¨¡å¼
        if not self.enable_thinking:
            improvement_prompt += "/no_think"
        
        return self.ollama_client.generate_stream(improvement_prompt)
    
    def regenerate_from_content_stream(self, content: str, language: str = "zh-CN"):
        """æµå¼ä»ç°æœ‰å†…å®¹é‡æ–°ç”Ÿæˆ"""
        # è·å–è¯­è¨€å‚æ•°
        try:
            lang = Language(language)
        except ValueError:
            lang = Language.ZH_CN
        
        # ä½¿ç”¨å›½é™…åŒ–æ¨¡æ¿
        prompt_template = get_prompt_template("regeneration_from_content", lang)
        regeneration_prompt = prompt_template.format(content=content)
        
        # æ·»åŠ è¯­è¨€æŒ‡ä»¤
        regeneration_prompt = add_language_instruction_to_prompt(regeneration_prompt, lang)
        
        # å¤„ç†æ€è€ƒæ¨¡å¼
        if not self.enable_thinking:
            regeneration_prompt += "/no_think"
        
        return self.ollama_client.generate_stream(regeneration_prompt)


def main():
    """æ¼”ç¤ºæ™ºèƒ½ä½“ä½¿ç”¨"""
    print("ğŸ‰ å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆæ™ºèƒ½ä½“å¯åŠ¨ä¸­...")
    
    # é…ç½®é€‰æ‹©
    print("ğŸ”§ é…ç½®é€‰é¡¹ï¼š")
    stream_choice = input("æ˜¯å¦å¯ç”¨æµå¼å“åº”ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").lower()
    enable_stream = stream_choice != 'n'
    
    thinking_choice = input("æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").lower()
    enable_thinking = thinking_choice != 'n'
    
    print(f"âœ… é…ç½®ï¼šæµå¼å“åº”={enable_stream}, æ€è€ƒæ¨¡å¼={enable_thinking}")
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = XiaohongshuAgent(enable_stream=enable_stream, enable_thinking=enable_thinking)
    
    # æ£€æŸ¥è®¾ç½®
    if not agent.check_setup():
        print("âŒ æ™ºèƒ½ä½“è®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡")
        return
    
    print("âœ… æ™ºèƒ½ä½“å‡†å¤‡å°±ç»ªï¼")
    print("=" * 50)
    
    # ç¤ºä¾‹ï¼šç”Ÿæˆç¾å¦†å†…å®¹
    print("ğŸ“ ç¤ºä¾‹ï¼šç”Ÿæˆç¾å¦†æŠ¤è‚¤å†…å®¹")
    request = ContentRequest(
        category=ContentCategory.BEAUTY,
        topic="å†¬å­£æŠ¤è‚¤ä¿æ¹¿æ”»ç•¥",
        tone="ä¸“ä¸šæ¸©å’Œ",
        keywords=["ä¿æ¹¿", "å†¬å­£", "æŠ¤è‚¤"],
        target_audience="20-30å²å¥³æ€§"
    )
    
    result = agent.generate_complete_post(request)
    
    if result["success"]:
        print("ç”Ÿæˆç»“æœï¼š")
        print(result["content"])
    else:
        print(f"ç”Ÿæˆå¤±è´¥ï¼š{result['error']}")
    
    print("=" * 50)
    print("ğŸ’¬ æ‚¨å¯ä»¥ç»§ç»­ä¸æ™ºèƒ½ä½“å¯¹è¯ï¼Œè¾“å…¥'quit'é€€å‡º")
    
    # äº¤äº’æ¨¡å¼
    while True:
        try:
            user_input = input("\næ‚¨ï¼š")
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                break
            
            response = agent.chat(user_input)
            print(f"\næ™ºèƒ½ä½“ï¼š{response}")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆæ™ºèƒ½ä½“ï¼")
            break


if __name__ == "__main__":
    main() 