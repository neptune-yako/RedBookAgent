"""
å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆæ™ºèƒ½ä½“
åŸºäºLangChainå’ŒOllamaæ„å»ºçš„æ™ºèƒ½æ–‡æ¡ˆç”Ÿæˆå·¥å…·
"""

import json
import sys
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥LLMæ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from LLM.ollama_client import OllamaClient

from langchain.agents import initialize_agent, AgentType
from langchain.tools import Tool
from langchain.memory import ConversationBufferMemory
from langchain.schema import BaseMessage, HumanMessage, AIMessage
from langchain.llms.base import LLM
from langchain.callbacks.manager import CallbackManagerForLLMRun
from pydantic import Field


class ContentCategory(Enum):
    """å†…å®¹åˆ†ç±»æšä¸¾"""
    BEAUTY = "ç¾å¦†æŠ¤è‚¤"
    FASHION = "æ—¶å°šç©¿æ­"
    FOOD = "ç¾é£Ÿæ¢åº—"
    TRAVEL = "æ—…è¡Œæ”»ç•¥"
    LIFESTYLE = "ç”Ÿæ´»æ–¹å¼"
    FITNESS = "å¥èº«è¿åŠ¨"
    HOME = "å®¶å±…è£…é¥°"
    STUDY = "å­¦ä¹ åˆ†äº«"
    WORK = "èŒåœºå¹²è´§"
    SHOPPING = "å¥½ç‰©æ¨è"


@dataclass
class ContentRequest:
    """å†…å®¹ç”Ÿæˆè¯·æ±‚"""
    category: ContentCategory
    topic: str
    tone: str = "æ´»æ³¼å¯çˆ±"
    length: str = "ä¸­ç­‰"
    keywords: List[str] = None
    target_audience: str = "å¹´è½»å¥³æ€§"
    special_requirements: str = ""


class OllamaLangChainLLM(LLM):
    """å°†Ollamaå®¢æˆ·ç«¯é€‚é…ä¸ºLangChainçš„LLMæ¥å£"""
    
    ollama_client: OllamaClient = Field(default_factory=lambda: OllamaClient())
    enable_stream: bool = Field(default=True)
    enable_thinking: bool = Field(default=True)
    
    @property
    def _llm_type(self) -> str:
        return "ollama"
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        """è°ƒç”¨Ollamaç”Ÿæˆæ–‡æœ¬"""
        # å¤„ç†æ€è€ƒæ¨¡å¼
        if not self.enable_thinking and not prompt.endswith("/no_think"):
            prompt += "/no_think"
        
        response = self.ollama_client.generate(prompt, stream=self.enable_stream)
        return response if response else "æŠ±æ­‰ï¼Œç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚"


class XiaohongshuAgent:
    """å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆæ™ºèƒ½ä½“"""
    
    def __init__(self, enable_stream: bool = True, enable_thinking: bool = True):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“
        
        Args:
            enable_stream: æ˜¯å¦å¯ç”¨æµå¼å“åº”
            enable_thinking: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼
        """
        self.ollama_client = OllamaClient()
        self.llm = OllamaLangChainLLM(
            enable_stream=enable_stream,
            enable_thinking=enable_thinking
        )
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        # å­˜å‚¨é…ç½®
        self.enable_stream = enable_stream
        self.enable_thinking = enable_thinking
        
        # åˆå§‹åŒ–å·¥å…·
        self.tools = self._create_tools()
        
        # åˆå§‹åŒ–æ™ºèƒ½ä½“
        self.agent = initialize_agent(
            tools=self.tools,
            llm=self.llm,
            agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
            memory=self.memory,
            verbose=True,
            handle_parsing_errors=True
        )
    
    def _create_tools(self) -> List[Tool]:
        """åˆ›å»ºæ™ºèƒ½ä½“ä½¿ç”¨çš„å·¥å…·"""
        
        def generate_title_tool(query: str) -> str:
            """ç”Ÿæˆå°çº¢ä¹¦æ ‡é¢˜çš„å·¥å…·"""
            prompt = f"""
ä½œä¸ºå°çº¢ä¹¦çˆ†æ¬¾æ ‡é¢˜ä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆ3ä¸ªå¸å¼•äººçš„æ ‡é¢˜ï¼š

å†…å®¹æè¿°ï¼š{query}

è¦æ±‚ï¼š
1. æ ‡é¢˜è¦æœ‰å¸å¼•åŠ›å’Œè¯é¢˜æ€§
2. é€‚å½“ä½¿ç”¨emojiè¡¨æƒ…
3. é•¿åº¦æ§åˆ¶åœ¨15-25å­—
4. ç¬¦åˆå°çº¢ä¹¦ç”¨æˆ·ä¹ æƒ¯
5. æ¯ä¸ªæ ‡é¢˜é£æ ¼è¦æœ‰å·®å¼‚
6.å¸¦emojiã€åˆ†æ®µæ¸…æ™°

è¯·ç”Ÿæˆ3ä¸ªæ ‡é¢˜ï¼Œç”¨åºå·åˆ†åˆ«æ ‡æ³¨ã€‚
"""
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                prompt += "/no_think"
            
            return self.ollama_client.generate(prompt, stream=self.enable_stream) or "ç”Ÿæˆå¤±è´¥"
        
        def generate_content_tool(query: str) -> str:
            """ç”Ÿæˆå°çº¢ä¹¦æ­£æ–‡å†…å®¹çš„å·¥å…·"""
            prompt = f"""
ä½œä¸ºå°çº¢ä¹¦å†…å®¹åˆ›ä½œä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦æ–‡æ¡ˆï¼š

éœ€æ±‚ï¼š{query}

è¦æ±‚ï¼š
1. å¼€å¤´è¦æœ‰å¸å¼•äººçš„hook
2. å†…å®¹è¦æœ‰ä»·å€¼å’Œå®ç”¨æ€§
3. å¸¦emojiã€åˆ†æ®µæ¸…æ™°
4. ç»“å°¾è¦æœ‰äº’åŠ¨å¼•å¯¼
5. æ•´ä½“é£æ ¼è¦ç¬¦åˆå°çº¢ä¹¦è°ƒæ€§
6. å­—æ•°æ§åˆ¶åœ¨200-500å­—

è¯·ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦æ–‡æ¡ˆã€‚
"""
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                prompt += "/no_think"
            
            return self.ollama_client.generate(prompt, stream=self.enable_stream) or "ç”Ÿæˆå¤±è´¥"
        
        def generate_hashtags_tool(query: str) -> str:
            """ç”Ÿæˆå°çº¢ä¹¦è¯é¢˜æ ‡ç­¾çš„å·¥å…·"""
            prompt = f"""
ä½œä¸ºå°çº¢ä¹¦è¯é¢˜æ ‡ç­¾ä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆç›¸å…³çš„è¯é¢˜æ ‡ç­¾ï¼š

å†…å®¹ï¼š{query}

è¦æ±‚ï¼š
1. ç”Ÿæˆ8-12ä¸ªç›¸å…³è¯é¢˜æ ‡ç­¾
2. åŒ…å«çƒ­é—¨æ ‡ç­¾å’Œç²¾å‡†æ ‡ç­¾
3. æ ‡ç­¾è¦ç¬¦åˆå°çº¢ä¹¦è§„èŒƒ
4. ç”¨#å·æ ‡æ³¨æ¯ä¸ªæ ‡ç­¾
5. æŒ‰ç…§çƒ­åº¦å’Œç›¸å…³æ€§æ’åº

è¯·ç”Ÿæˆè¯é¢˜æ ‡ç­¾åˆ—è¡¨ã€‚
"""
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                prompt += "/no_think"
            
            return self.ollama_client.generate(prompt, stream=self.enable_stream) or "ç”Ÿæˆå¤±è´¥"
        
        def content_optimization_tool(query: str) -> str:
            """å†…å®¹ä¼˜åŒ–å»ºè®®å·¥å…·"""
            prompt = f"""
ä½œä¸ºå°çº¢ä¹¦å†…å®¹ä¼˜åŒ–ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹æ–‡æ¡ˆæä¾›ä¼˜åŒ–å»ºè®®ï¼š

æ–‡æ¡ˆå†…å®¹ï¼š{query}

è¯·ä»ä»¥ä¸‹è§’åº¦æä¾›ä¼˜åŒ–å»ºè®®ï¼š
1. æ ‡é¢˜å¸å¼•åŠ›
2. å†…å®¹ç»“æ„
3. ç”¨è¯ä¼˜åŒ–
4. emojiä½¿ç”¨
5. äº’åŠ¨æ€§æå‡
6. SEOä¼˜åŒ–

è¯·æä¾›å…·ä½“çš„ä¼˜åŒ–å»ºè®®å’Œä¿®æ”¹å»ºè®®ã€‚
"""
            # å¤„ç†æ€è€ƒæ¨¡å¼
            if not self.enable_thinking:
                prompt += "/no_think"
            
            return self.ollama_client.generate(prompt, stream=self.enable_stream) or "ç”Ÿæˆå¤±è´¥"
        
        return [
            Tool(
                name="ç”Ÿæˆæ ‡é¢˜",
                func=generate_title_tool,
                description="ä¸ºå°çº¢ä¹¦å†…å®¹ç”Ÿæˆå¸å¼•äººçš„æ ‡é¢˜ï¼Œè¾“å…¥å†…å®¹æè¿°å³å¯"
            ),
            Tool(
                name="ç”Ÿæˆæ­£æ–‡",
                func=generate_content_tool,
                description="æ ¹æ®éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦æ–‡æ¡ˆæ­£æ–‡å†…å®¹"
            ),
            Tool(
                name="ç”Ÿæˆè¯é¢˜æ ‡ç­¾",
                func=generate_hashtags_tool,
                description="ä¸ºå°çº¢ä¹¦å†…å®¹ç”Ÿæˆç›¸å…³çš„è¯é¢˜æ ‡ç­¾"
            ),
            Tool(
                name="å†…å®¹ä¼˜åŒ–",
                func=content_optimization_tool,
                description="å¯¹å·²æœ‰çš„å°çº¢ä¹¦æ–‡æ¡ˆæä¾›ä¼˜åŒ–å»ºè®®å’Œæ”¹è¿›æ–¹æ¡ˆ"
            )
        ]
    
    def check_setup(self) -> bool:
        """æ£€æŸ¥æ™ºèƒ½ä½“è®¾ç½®çŠ¶æ€"""
        print("ğŸ” æ­£åœ¨æ£€æŸ¥æ™ºèƒ½ä½“è®¾ç½®...")
        
        # æ£€æŸ¥Ollamaè¿æ¥
        if not self.ollama_client.check_connection():
            print("âŒ OllamaæœåŠ¡è¿æ¥å¤±è´¥")
            return False
        print("âœ… OllamaæœåŠ¡è¿æ¥æ­£å¸¸")
        
        # æ£€æŸ¥æ¨¡å‹
        if not self.ollama_client.check_model_exists():
            print("âš ï¸  æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¸‹è½½...")
            if not self.ollama_client.pull_model():
                print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
                return False
        print("âœ… æ¨¡å‹å‡†å¤‡å°±ç»ª")
        
        return True
    
    def generate_complete_post(self, request: ContentRequest) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦æ–‡æ¡ˆ"""
        
        # æ„å»ºè¯¦ç»†çš„éœ€æ±‚æè¿°
        requirement = f"""
è¯·ä¸ºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦æ–‡æ¡ˆï¼š

åˆ†ç±»ï¼š{request.category.value}
ä¸»é¢˜ï¼š{request.topic}
è¯­æ°”é£æ ¼ï¼š{request.tone}
é•¿åº¦ï¼š{request.length}
ç›®æ ‡å—ä¼—ï¼š{request.target_audience}
"""
        
        if request.keywords:
            requirement += f"å…³é”®è¯ï¼š{', '.join(request.keywords)}\n"
        
        if request.special_requirements:
            requirement += f"ç‰¹æ®Šè¦æ±‚ï¼š{request.special_requirements}\n"
        
        requirement += "\nè¯·åˆ†åˆ«ç”Ÿæˆæ ‡é¢˜ã€æ­£æ–‡å†…å®¹å’Œè¯é¢˜æ ‡ç­¾ã€‚"
        
        try:
            # ä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆå†…å®¹
            result = self.agent.run(requirement)
            
            return {
                "success": True,
                "content": result,
                "request": request.__dict__
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "request": request.__dict__
            }
    
    def optimize_content(self, content: str) -> Dict[str, Any]:
        """ä¼˜åŒ–ç°æœ‰å†…å®¹"""
        try:
            optimization_query = f"è¯·ä¼˜åŒ–ä»¥ä¸‹å°çº¢ä¹¦æ–‡æ¡ˆï¼š\n\n{content}"
            result = self.agent.run(optimization_query)
            
            return {
                "success": True,
                "original": content,
                "optimized": result
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "original": content
            }
    
    def chat(self, message: str) -> str:
        """ä¸æ™ºèƒ½ä½“å¯¹è¯"""
        try:
            response = self.agent.run(message)
            return response
        except Exception as e:
            return f"å¯¹è¯å‡ºé”™ï¼š{str(e)}"
    
    def update_config(self, enable_stream: bool = None, enable_thinking: bool = None):
        """æ›´æ–°é…ç½®"""
        if enable_stream is not None:
            self.enable_stream = enable_stream
            self.llm.enable_stream = enable_stream
        
        if enable_thinking is not None:
            self.enable_thinking = enable_thinking
            self.llm.enable_thinking = enable_thinking
    


    def generate_complete_post_stream(self, request: ContentRequest):
        """æµå¼ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦æ–‡æ¡ˆ"""
        
        # æ„å»ºè¯¦ç»†çš„éœ€æ±‚æè¿°
        requirement = f"""
è¯·ä¸ºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦æ–‡æ¡ˆï¼š

åˆ†ç±»ï¼š{request.category.value}
ä¸»é¢˜ï¼š{request.topic}
è¯­æ°”é£æ ¼ï¼š{request.tone}
é•¿åº¦ï¼š{request.length}
ç›®æ ‡å—ä¼—ï¼š{request.target_audience}
"""
        
        if request.keywords:
            requirement += f"å…³é”®è¯ï¼š{', '.join(request.keywords)}\n"
        
        if request.special_requirements:
            requirement += f"ç‰¹æ®Šè¦æ±‚ï¼š{request.special_requirements}\n"
        
        requirement += "\nè¯·åˆ†åˆ«ç”Ÿæˆæ ‡é¢˜ã€æ­£æ–‡å†…å®¹å’Œè¯é¢˜æ ‡ç­¾ã€‚"
        
        # å¤„ç†æ€è€ƒæ¨¡å¼
        if not self.enable_thinking:
            requirement += "/no_think"
        
        # ä½¿ç”¨æµå¼ç”Ÿæˆå™¨
        return self.ollama_client.generate_stream(requirement)
    
    def chat_stream(self, message: str):
        """æµå¼å¯¹è¯"""
        try:
            # æ„å»ºå¯¹è¯æ¶ˆæ¯
            messages = [{"role": "user", "content": message}]
            
            # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
            chat_history = self.memory.chat_memory.messages
            if chat_history:
                # è½¬æ¢LangChainæ¶ˆæ¯æ ¼å¼åˆ°Ollamaæ ¼å¼
                for msg in chat_history[-10:]:  # åªä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
                    if hasattr(msg, 'content'):
                        if isinstance(msg, HumanMessage):
                            messages.insert(-1, {"role": "user", "content": msg.content})
                        elif isinstance(msg, AIMessage):
                            messages.insert(-1, {"role": "assistant", "content": msg.content})
            
            # ä½¿ç”¨æµå¼ç”Ÿæˆå™¨
            return self.ollama_client.chat_stream(messages)
        except Exception as e:
            def error_generator():
                yield f"å¯¹è¯å‡ºé”™ï¼š{str(e)}"
            return error_generator()
    
    def optimize_content_stream(self, content: str):
        """æµå¼ä¼˜åŒ–ç°æœ‰å†…å®¹"""
        optimization_query = f"è¯·ä¼˜åŒ–ä»¥ä¸‹å°çº¢ä¹¦æ–‡æ¡ˆï¼š\n\n{content}"
        
        # å¤„ç†æ€è€ƒæ¨¡å¼
        if not self.enable_thinking:
            optimization_query += "/no_think"
        
        # ä½¿ç”¨æµå¼ç”Ÿæˆå™¨
        return self.ollama_client.generate_stream(optimization_query)


def main():
    """æ¼”ç¤ºæ™ºèƒ½ä½“ä½¿ç”¨"""
    print("ğŸ‰ å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆæ™ºèƒ½ä½“å¯åŠ¨ä¸­...")
    
    # é…ç½®é€‰æ‹©
    print("ğŸ”§ é…ç½®é€‰é¡¹ï¼š")
    stream_choice = input("æ˜¯å¦å¯ç”¨æµå¼å“åº”ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").lower()
    enable_stream = stream_choice != 'n'
    
    thinking_choice = input("æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").lower()
    enable_thinking = thinking_choice != 'n'
    
    print(f"âœ… é…ç½®ï¼šæµå¼å“åº”={enable_stream}, æ€è€ƒæ¨¡å¼={enable_thinking}")
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = XiaohongshuAgent(enable_stream=enable_stream, enable_thinking=enable_thinking)
    
    # æ£€æŸ¥è®¾ç½®
    if not agent.check_setup():
        print("âŒ æ™ºèƒ½ä½“è®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡")
        return
    
    print("âœ… æ™ºèƒ½ä½“å‡†å¤‡å°±ç»ªï¼")
    print("=" * 50)
    
    # ç¤ºä¾‹ï¼šç”Ÿæˆç¾å¦†å†…å®¹
    print("ğŸ“ ç¤ºä¾‹ï¼šç”Ÿæˆç¾å¦†æŠ¤è‚¤å†…å®¹")
    request = ContentRequest(
        category=ContentCategory.BEAUTY,
        topic="å†¬å­£æŠ¤è‚¤ä¿æ¹¿æ”»ç•¥",
        tone="ä¸“ä¸šæ¸©å’Œ",
        keywords=["ä¿æ¹¿", "å†¬å­£", "æŠ¤è‚¤"],
        target_audience="20-30å²å¥³æ€§"
    )
    
    result = agent.generate_complete_post(request)
    
    if result["success"]:
        print("ç”Ÿæˆç»“æœï¼š")
        print(result["content"])
    else:
        print(f"ç”Ÿæˆå¤±è´¥ï¼š{result['error']}")
    
    print("=" * 50)
    print("ğŸ’¬ æ‚¨å¯ä»¥ç»§ç»­ä¸æ™ºèƒ½ä½“å¯¹è¯ï¼Œè¾“å…¥'quit'é€€å‡º")
    
    # äº¤äº’æ¨¡å¼
    while True:
        try:
            user_input = input("\næ‚¨ï¼š")
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                break
            
            response = agent.chat(user_input)
            print(f"\næ™ºèƒ½ä½“ï¼š{response}")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆæ™ºèƒ½ä½“ï¼")
            break


if __name__ == "__main__":
    main() 